{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5456a734",
   "metadata": {},
   "source": [
    "### GridWorld Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28b62321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "\n",
    "class DeliveryGridWorld(gym.Env):\n",
    "    \"\"\"\n",
    "    A gridworld environment for multiple delivery bots.\n",
    "    \n",
    "    Each agent needs to pick up packages and deliver them to destinations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, grid_size=10, num_agents=4, num_packages=8, max_steps=200):\n",
    "        super(DeliveryGridWorld, self).__init__()\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        self.num_agents = num_agents\n",
    "        self.num_packages = num_packages\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Action space: move up, down, left, right, pickup/deliver\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "        \n",
    "        # Observation space per agent: \n",
    "        # - Agent position (x, y)\n",
    "        # - Agent carrying status\n",
    "        # - Positions of all packages with delivery status\n",
    "        # - Positions of all destinations\n",
    "        # - Positions of other agents\n",
    "        \n",
    "        obs_size = 2 + 1 + (3 * num_packages) + (2 * num_packages) + (2 * num_agents - 2)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=grid_size-1, shape=(obs_size,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Initialize grid and positions\n",
    "        self.grid = np.zeros((grid_size, grid_size), dtype=int)\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Reset the environment to initial state.\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Clear grid\n",
    "        self.grid = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
    "        \n",
    "        # Initialize agent positions (avoid collisions)\n",
    "        self.agent_positions = []\n",
    "        self.agent_carrying = [None] * self.num_agents\n",
    "        \n",
    "        for _ in range(self.num_agents):\n",
    "            while True:\n",
    "                pos = (\n",
    "                    self.np_random.integers(0, self.grid_size),\n",
    "                    self.np_random.integers(0, self.grid_size)\n",
    "                )\n",
    "                if pos not in self.agent_positions:\n",
    "                    self.agent_positions.append(pos)\n",
    "                    break\n",
    "        \n",
    "        # Initialize package positions and destinations\n",
    "        self.packages = []\n",
    "        self.destinations = []\n",
    "        self.package_status = [0] * self.num_packages  # 0: waiting, 1: picked, 2: delivered\n",
    "        \n",
    "        # Define package-destination mapping - CRITICAL FIX\n",
    "        self.package_destinations = list(range(self.num_packages))\n",
    "        \n",
    "        for _ in range(self.num_packages):\n",
    "            # Package position\n",
    "            while True:\n",
    "                pkg_pos = (\n",
    "                    self.np_random.integers(0, self.grid_size),\n",
    "                    self.np_random.integers(0, self.grid_size)\n",
    "                )\n",
    "                if (pkg_pos not in self.agent_positions and \n",
    "                    pkg_pos not in self.packages):\n",
    "                    self.packages.append(pkg_pos)\n",
    "                    break\n",
    "            \n",
    "            # Destination position\n",
    "            while True:\n",
    "                dest_pos = (\n",
    "                    self.np_random.integers(0, self.grid_size),\n",
    "                    self.np_random.integers(0, self.grid_size)\n",
    "                )\n",
    "                if (dest_pos not in self.agent_positions and \n",
    "                    dest_pos not in self.packages and\n",
    "                    dest_pos not in self.destinations):\n",
    "                    self.destinations.append(dest_pos)\n",
    "                    break\n",
    "        \n",
    "        # Print initial state for debugging\n",
    "        print(\"Environment Reset\")\n",
    "        print(f\"Grid Size: {self.grid_size}x{self.grid_size}\")\n",
    "        print(f\"Number of Agents: {self.num_agents}\")\n",
    "        print(f\"Number of Packages: {self.num_packages}\")\n",
    "        print(f\"Agent Positions: {self.agent_positions}\")\n",
    "        print(f\"Package Positions: {self.packages}\")\n",
    "        print(f\"Destination Positions: {self.destinations}\")\n",
    "        print(f\"Package-Destination Mapping: {self.package_destinations}\")\n",
    "        \n",
    "        return self._get_observations(), {}\n",
    "    \n",
    "    def _get_observations(self):\n",
    "        \"\"\"Get observations for all agents.\"\"\"\n",
    "        observations = {}\n",
    "        \n",
    "        for agent_id in range(self.num_agents):\n",
    "            obs = self._get_agent_observation(agent_id)\n",
    "            observations[agent_id] = obs\n",
    "            \n",
    "        return observations\n",
    "    \n",
    "    def _get_agent_observation(self, agent_id):\n",
    "        \"\"\"Get observation for a specific agent.\"\"\"\n",
    "        agent_pos = self.agent_positions[agent_id]\n",
    "        \n",
    "        # Agent's own position\n",
    "        obs = [agent_pos[0] / (self.grid_size - 1), agent_pos[1] / (self.grid_size - 1)]\n",
    "        \n",
    "        # Carrying status (0 if not carrying, index+1 of package if carrying)\n",
    "        carrying = 0 if self.agent_carrying[agent_id] is None else self.agent_carrying[agent_id] + 1\n",
    "        obs.append(carrying / (self.num_packages + 1))\n",
    "        \n",
    "        # Package positions and status\n",
    "        for i in range(self.num_packages):\n",
    "            if self.package_status[i] == 2:  # Delivered\n",
    "                # Use (-1, -1) for delivered packages\n",
    "                obs.extend([-1.0, -1.0, 1.0])\n",
    "            else:\n",
    "                package_pos = self.packages[i]\n",
    "                obs.extend([\n",
    "                    package_pos[0] / (self.grid_size - 1),\n",
    "                    package_pos[1] / (self.grid_size - 1),\n",
    "                    self.package_status[i] / 2.0  # Normalize status\n",
    "                ])\n",
    "        \n",
    "        # Destination positions\n",
    "        for dest_pos in self.destinations:\n",
    "            obs.extend([dest_pos[0] / (self.grid_size - 1), dest_pos[1] / (self.grid_size - 1)])\n",
    "        \n",
    "        # Other agents' positions\n",
    "        for i in range(self.num_agents):\n",
    "            if i != agent_id:\n",
    "                other_pos = self.agent_positions[i]\n",
    "                obs.extend([other_pos[0] / (self.grid_size - 1), other_pos[1] / (self.grid_size - 1)])\n",
    "        \n",
    "        return np.array(obs, dtype=np.float32)\n",
    "    \n",
    "    def step(self, actions):\n",
    "        \"\"\"Execute actions for all agents.\"\"\"\n",
    "        self.current_step += 1\n",
    "        \n",
    "        rewards = {agent_id: 0.0 for agent_id in range(self.num_agents)}\n",
    "        infos = {agent_id: {} for agent_id in range(self.num_agents)}\n",
    "        \n",
    "        # Print current state before actions\n",
    "        if self.current_step % 10 == 0:\n",
    "            print(f\"\\n--- Step {self.current_step} ---\")\n",
    "            print(f\"Agent Positions: {self.agent_positions}\")\n",
    "            for i in range(self.num_agents):\n",
    "                carrying = \"None\" if self.agent_carrying[i] is None else f\"Package {self.agent_carrying[i]}\"\n",
    "                print(f\"Agent {i} at {self.agent_positions[i]} carrying: {carrying}\")\n",
    "        \n",
    "        # Process movements (with collision prevention)\n",
    "        new_positions = []\n",
    "        \n",
    "        for agent_id, action in actions.items():\n",
    "            # Get current position\n",
    "            current_pos = self.agent_positions[agent_id]\n",
    "            new_pos = list(current_pos)\n",
    "            \n",
    "            # Movement actions\n",
    "            if action == 0:  # Up\n",
    "                new_pos[1] = max(0, current_pos[1] - 1)\n",
    "            elif action == 1:  # Down\n",
    "                new_pos[1] = min(self.grid_size - 1, current_pos[1] + 1)\n",
    "            elif action == 2:  # Left\n",
    "                new_pos[0] = max(0, current_pos[0] - 1)\n",
    "            elif action == 3:  # Right\n",
    "                new_pos[0] = min(self.grid_size - 1, current_pos[0] + 1)\n",
    "            \n",
    "            new_positions.append(tuple(new_pos))\n",
    "            \n",
    "            if self.current_step % 10 == 0:\n",
    "                print(f\"Agent {agent_id} action: {action} (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\")\n",
    "                if action < 4:\n",
    "                    print(f\"  Moving from {current_pos} to {new_pos}\")\n",
    "        \n",
    "        # Check for collisions and update positions\n",
    "        for agent_id, new_pos in enumerate(new_positions):\n",
    "            # Only move if no collision with another agent\n",
    "            collision = False\n",
    "            for other_id, other_new_pos in enumerate(new_positions):\n",
    "                if agent_id != other_id and new_pos == other_new_pos:\n",
    "                    collision = True\n",
    "                    break\n",
    "            \n",
    "            if not collision and new_pos not in self.agent_positions[:agent_id] + self.agent_positions[agent_id+1:]:\n",
    "                self.agent_positions[agent_id] = new_pos\n",
    "            else:\n",
    "                # Small penalty for collision\n",
    "                rewards[agent_id] -= 0.1\n",
    "                if self.current_step % 10 == 0:\n",
    "                    print(f\"  Agent {agent_id} collision detected! Staying at {self.agent_positions[agent_id]}\")\n",
    "        \n",
    "        # Process pickup/deliver actions\n",
    "        for agent_id, action in actions.items():\n",
    "            if action == 4:  # Pickup or deliver\n",
    "                current_pos = self.agent_positions[agent_id]\n",
    "                \n",
    "                if self.agent_carrying[agent_id] is None:\n",
    "                    # Try to pick up a package\n",
    "                    for pkg_idx, pkg_pos in enumerate(self.packages):\n",
    "                        if current_pos == pkg_pos and self.package_status[pkg_idx] == 0:\n",
    "                            self.agent_carrying[agent_id] = pkg_idx\n",
    "                            self.package_status[pkg_idx] = 1\n",
    "                            rewards[agent_id] += 1.0  # Reward for picking up\n",
    "                            print(f\"Agent {agent_id} picked up package {pkg_idx} at {current_pos}\")\n",
    "\n",
    "\n",
    "                            break\n",
    "                else:\n",
    "                    # Try to deliver a package\n",
    "                    pkg_idx = self.agent_carrying[agent_id]\n",
    "                    dest_idx = self.package_destinations[pkg_idx]  # Get the correct destination for this package\n",
    "                    \n",
    "                    if current_pos == self.destinations[dest_idx]:\n",
    "                        self.package_status[pkg_idx] = 2  # Mark as delivered\n",
    "                        self.agent_carrying[agent_id] = None\n",
    "                        rewards[agent_id] += 5.0  # Larger reward for delivery\n",
    "                        print(f\"ðŸŽ‰ SUCCESS! Agent {agent_id} delivered package {pkg_idx} to destination {dest_idx} at {current_pos}\")\n",
    "                    else:\n",
    "                        if self.current_step % 10 == 0:\n",
    "                            print(f\"Agent {agent_id} tried to deliver package {pkg_idx} at {current_pos} but this is not destination {dest_idx} ({self.destinations[dest_idx]})\")\n",
    "        \n",
    "        # Small penalty for each step to encourage efficiency\n",
    "        for agent_id in range(self.num_agents):\n",
    "            rewards[agent_id] -= 0.01\n",
    "        \n",
    "        # Check if all packages are delivered\n",
    "        done = all(status == 2 for status in self.package_status)\n",
    "        \n",
    "        # Print delivery status\n",
    "        if self.current_step % 10 == 0:\n",
    "            delivered_count = sum(1 for status in self.package_status if status == 2)\n",
    "            print(f\"Packages delivered: {delivered_count}/{self.num_packages}\")\n",
    "            for i, status in enumerate(self.package_status):\n",
    "                status_text = \"Not Picked\" if status == 0 else (\"Picked Up\" if status == 1 else \"Delivered\")\n",
    "                print(f\"  Package {i}: {status_text}\")\n",
    "        \n",
    "        # Check if max steps reached\n",
    "        if self.current_step >= self.max_steps:\n",
    "            print(f\"\\nMax steps ({self.max_steps}) reached!\")\n",
    "            done = True\n",
    "        \n",
    "        truncated = {agent_id: False for agent_id in range(self.num_agents)}\n",
    "        dones = {agent_id: done for agent_id in range(self.num_agents)}\n",
    "        dones[\"__all__\"] = done\n",
    "        \n",
    "        return self._get_observations(), rewards, dones, truncated, infos\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"Simple text-based rendering.\"\"\"\n",
    "        grid_render = [['.' for _ in range(self.grid_size)] for _ in range(self.grid_size)]\n",
    "        \n",
    "        # Mark destinations\n",
    "        for i, dest_pos in enumerate(self.destinations):\n",
    "            grid_render[dest_pos[1]][dest_pos[0]] = f'D{i}'\n",
    "        \n",
    "        # Mark packages\n",
    "        for i, pkg_pos in enumerate(self.packages):\n",
    "            if self.package_status[i] == 0:  # Only show if not picked up\n",
    "                grid_render[pkg_pos[1]][pkg_pos[0]] = f'P{i}'\n",
    "        \n",
    "        # Mark agents\n",
    "        for i, agent_pos in enumerate(self.agent_positions):\n",
    "            carrying = ''\n",
    "            if self.agent_carrying[i] is not None:\n",
    "                carrying = f'({self.agent_carrying[i]})'\n",
    "            grid_render[agent_pos[1]][agent_pos[0]] = f'A{i}{carrying}'\n",
    "        \n",
    "        # Print grid\n",
    "        for row in grid_render:\n",
    "            print(' '.join(row))\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    def get_sumo_data(self):\n",
    "        \"\"\"\n",
    "        Return data that can be used for SUMO visualization.\n",
    "        \"\"\"\n",
    "        sumo_data = {\n",
    "            'grid_size': self.grid_size,\n",
    "            'agents': [],\n",
    "            'packages': [],\n",
    "            'destinations': []\n",
    "        }\n",
    "        \n",
    "        # Agent data\n",
    "        for i, pos in enumerate(self.agent_positions):\n",
    "            agent_data = {\n",
    "                'id': i,\n",
    "                'x': pos[0],\n",
    "                'y': pos[1],\n",
    "                'carrying': self.agent_carrying[i]\n",
    "            }\n",
    "            sumo_data['agents'].append(agent_data)\n",
    "        \n",
    "        # Package data\n",
    "        for i in range(self.num_packages):\n",
    "            if self.package_status[i] < 2:  # Only include non-delivered packages\n",
    "                pkg_data = {\n",
    "                    'id': i,\n",
    "                    'x': self.packages[i][0],\n",
    "                    'y': self.packages[i][1],\n",
    "                    'status': self.package_status[i]\n",
    "                }\n",
    "                sumo_data['packages'].append(pkg_data)\n",
    "        \n",
    "        # Destination data\n",
    "        for i, pos in enumerate(self.destinations):\n",
    "            dest_data = {\n",
    "                'id': i,\n",
    "                'x': pos[0],\n",
    "                'y': pos[1]\n",
    "            }\n",
    "            sumo_data['destinations'].append(dest_data)\n",
    "        \n",
    "        return sumo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6513f19",
   "metadata": {},
   "source": [
    "## PPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0186b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, n_actions, alpha=0.0003):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(input_dims, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        dist = self.actor(state)\n",
    "        dist = Categorical(dist)\n",
    "        \n",
    "        return dist\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, alpha=0.0003):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(input_dims, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "        \n",
    "        return value\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, input_dims, n_actions, gamma=0.99, alpha=0.0003, \n",
    "                 gae_lambda=0.95, policy_clip=0.2, batch_size=64, \n",
    "                 n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "        \n",
    "        self.actor = ActorNetwork(input_dims, n_actions, alpha)\n",
    "        self.critic = CriticNetwork(input_dims, alpha)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "    \n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
    "    \n",
    "    def save_models(self, path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        torch.save(self.actor.state_dict(), os.path.join(path, 'actor.pth'))\n",
    "        torch.save(self.critic.state_dict(), os.path.join(path, 'critic.pth'))\n",
    "    \n",
    "    # def load_models(self, path):\n",
    "    #     self.actor.load_state_dict(torch.load(os.path.join(path, 'actor.pth')))\n",
    "    #     self.critic.load_state_dict(torch.load(os.path.join(path, 'critic.pth')))\n",
    "\n",
    "    def load_models(self, path):\n",
    "        actor_state_dict = torch.load(os.path.join(path, 'actor.pth'))\n",
    "        critic_state_dict = torch.load(os.path.join(path, 'critic.pth'))\n",
    "        \n",
    "        # Get the input dimension from the saved model\n",
    "        input_dims = actor_state_dict['actor.0.weight'].shape[1]\n",
    "        \n",
    "        # Recreate the networks with the correct input size\n",
    "        self.actor = ActorNetwork(input_dims, self.actor.actor[-2].out_features)\n",
    "        self.critic = CriticNetwork(input_dims)\n",
    "        \n",
    "        # Load the state dictionaries\n",
    "        self.actor.load_state_dict(actor_state_dict)\n",
    "        self.critic.load_state_dict(critic_state_dict)\n",
    "    \n",
    "    def choose_action(self, observation):\n",
    "        state = torch.tensor([observation], dtype=torch.float).to(device)\n",
    "        \n",
    "        dist = self.actor(state)\n",
    "        value = self.critic(state)\n",
    "        action = dist.sample()\n",
    "        \n",
    "        probs = torch.squeeze(dist.log_prob(action)).item()\n",
    "        action = torch.squeeze(action).item()\n",
    "        value = torch.squeeze(value).item()\n",
    "        \n",
    "        return action, probs, value\n",
    "    \n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr, \\\n",
    "            reward_arr, dones_arr, batches = self.memory.generate_batches()\n",
    "            \n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "            \n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount * (reward_arr[k] + self.gamma * values[k+1] * (1-dones_arr[k]) - values[k])\n",
    "                    discount *= self.gamma * self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            \n",
    "            advantage = torch.tensor(advantage).to(device)\n",
    "            values = torch.tensor(values).to(device)\n",
    "            \n",
    "            for batch in batches:\n",
    "                states = torch.tensor(state_arr[batch], dtype=torch.float).to(device)\n",
    "                old_probs = torch.tensor(old_prob_arr[batch]).to(device)\n",
    "                actions = torch.tensor(action_arr[batch]).to(device)\n",
    "                \n",
    "                dist = self.actor(states)\n",
    "                critic_value = self.critic(states)\n",
    "                \n",
    "                critic_value = torch.squeeze(critic_value)\n",
    "                \n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = torch.clamp(prob_ratio, 1-self.policy_clip, 1+self.policy_clip) * advantage[batch]\n",
    "                \n",
    "                actor_loss = -torch.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "                \n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns - critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "                \n",
    "                total_loss = actor_loss + 0.5 * critic_loss\n",
    "                \n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "        \n",
    "        self.memory.clear_memory()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a7c0ce",
   "metadata": {},
   "source": [
    "### PPO memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc00a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def store_memory(self, state, action, prob, val, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(prob)\n",
    "        self.vals.append(val)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "    \n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "    \n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype=np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "        \n",
    "        return np.array(self.states), np.array(self.actions), \\\n",
    "               np.array(self.probs), np.array(self.vals), \\\n",
    "               np.array(self.rewards), np.array(self.dones), batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4341fb",
   "metadata": {},
   "source": [
    "### Training the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d75360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Score: 0.4, Avg Score: 0.4\n",
      "Episode: 10, Score: -6.7, Avg Score: -4.7\n",
      "Episode: 20, Score: -7.5, Avg Score: -5.3\n",
      "Episode: 30, Score: -2.0, Avg Score: -4.4\n",
      "Episode: 40, Score: -1.9, Avg Score: -4.5\n",
      "Episode: 50, Score: -10.4, Avg Score: -4.3\n",
      "Episode: 60, Score: -2.0, Avg Score: -4.5\n",
      "Episode: 70, Score: -3.6, Avg Score: -4.6\n",
      "Episode: 80, Score: -9.3, Avg Score: -4.8\n",
      "Episode: 90, Score: -5.9, Avg Score: -4.9\n",
      "Episode: 100, Score: -6.7, Avg Score: -5.1\n",
      "Episode: 110, Score: -5.5, Avg Score: -5.4\n",
      "Episode: 120, Score: -5.2, Avg Score: -5.4\n",
      "Episode: 130, Score: -4.2, Avg Score: -5.5\n",
      "Episode: 140, Score: -4.4, Avg Score: -5.5\n",
      "Episode: 150, Score: -6.9, Avg Score: -5.7\n",
      "Episode: 160, Score: -1.5, Avg Score: -5.7\n",
      "Episode: 170, Score: -0.5, Avg Score: -5.6\n",
      "Episode: 180, Score: -7.0, Avg Score: -5.6\n",
      "Episode: 190, Score: -6.9, Avg Score: -5.3\n",
      "Episode: 200, Score: -6.1, Avg Score: -5.4\n",
      "Episode: 210, Score: -6.6, Avg Score: -5.1\n",
      "Episode: 220, Score: -4.4, Avg Score: -4.8\n",
      "Episode: 230, Score: -5.9, Avg Score: -5.1\n",
      "Episode: 240, Score: -3.2, Avg Score: -5.1\n",
      "Episode: 250, Score: -5.9, Avg Score: -5.2\n",
      "Episode: 260, Score: -5.8, Avg Score: -5.1\n",
      "Episode: 270, Score: -5.0, Avg Score: -5.2\n",
      "Episode: 280, Score: -5.7, Avg Score: -5.0\n",
      "Episode: 290, Score: 6.4, Avg Score: -5.0\n",
      "Episode: 300, Score: -5.9, Avg Score: -4.9\n",
      "Episode: 310, Score: -6.1, Avg Score: -4.8\n",
      "Episode: 320, Score: -7.4, Avg Score: -4.9\n",
      "Episode: 330, Score: -8.2, Avg Score: -4.9\n",
      "Episode: 340, Score: -6.6, Avg Score: -5.1\n",
      "Episode: 350, Score: -9.1, Avg Score: -5.0\n",
      "Episode: 360, Score: -1.2, Avg Score: -4.9\n",
      "Episode: 370, Score: -0.6, Avg Score: -5.0\n",
      "Episode: 380, Score: -8.9, Avg Score: -5.3\n",
      "Episode: 390, Score: -8.3, Avg Score: -5.5\n",
      "Episode: 400, Score: -13.1, Avg Score: -5.3\n",
      "Episode: 410, Score: -6.9, Avg Score: -5.4\n",
      "Episode: 420, Score: -2.0, Avg Score: -5.3\n",
      "Episode: 430, Score: -3.7, Avg Score: -5.3\n",
      "Episode: 440, Score: -7.4, Avg Score: -5.0\n",
      "Episode: 450, Score: -1.5, Avg Score: -4.6\n",
      "Episode: 460, Score: 2.7, Avg Score: -5.0\n",
      "Episode: 470, Score: -1.4, Avg Score: -5.0\n",
      "Episode: 480, Score: -3.7, Avg Score: -4.8\n",
      "Episode: 490, Score: -1.7, Avg Score: -4.7\n",
      "Episode: 500, Score: -0.4, Avg Score: -4.8\n",
      "Episode: 510, Score: -8.5, Avg Score: -4.8\n",
      "Episode: 520, Score: -1.1, Avg Score: -5.0\n",
      "Episode: 530, Score: -0.5, Avg Score: -4.9\n",
      "Episode: 540, Score: -6.2, Avg Score: -5.1\n",
      "Episode: 550, Score: -9.2, Avg Score: -5.7\n",
      "Episode: 560, Score: -6.2, Avg Score: -5.6\n",
      "Episode: 570, Score: -8.4, Avg Score: -6.0\n",
      "Episode: 580, Score: -5.7, Avg Score: -6.0\n",
      "Episode: 590, Score: -7.1, Avg Score: -6.1\n",
      "Episode: 600, Score: -9.1, Avg Score: -6.2\n",
      "Episode: 610, Score: -7.2, Avg Score: -6.2\n",
      "Episode: 620, Score: -0.2, Avg Score: -6.1\n",
      "Episode: 630, Score: 2.9, Avg Score: -6.2\n",
      "Episode: 640, Score: -1.9, Avg Score: -6.2\n",
      "Episode: 650, Score: -1.0, Avg Score: -5.7\n",
      "Episode: 660, Score: 0.6, Avg Score: -5.5\n",
      "Episode: 670, Score: -6.5, Avg Score: -5.4\n",
      "Episode: 680, Score: -6.3, Avg Score: -5.3\n",
      "Episode: 690, Score: -6.7, Avg Score: -5.3\n",
      "Episode: 700, Score: -5.7, Avg Score: -5.2\n",
      "Episode: 710, Score: -6.7, Avg Score: -5.3\n",
      "Episode: 720, Score: -17.9, Avg Score: -5.5\n",
      "Episode: 730, Score: -1.4, Avg Score: -5.4\n",
      "Episode: 740, Score: -2.8, Avg Score: -5.1\n",
      "Episode: 750, Score: -1.8, Avg Score: -5.2\n",
      "Episode: 760, Score: -4.8, Avg Score: -5.0\n",
      "Episode: 770, Score: -4.3, Avg Score: -4.7\n",
      "Episode: 780, Score: -6.1, Avg Score: -4.8\n",
      "Episode: 790, Score: -4.6, Avg Score: -4.6\n",
      "Episode: 800, Score: -5.6, Avg Score: -4.3\n",
      "Episode: 810, Score: -7.9, Avg Score: -4.4\n",
      "Episode: 820, Score: -6.2, Avg Score: -4.4\n",
      "Episode: 830, Score: -6.2, Avg Score: -4.3\n",
      "Episode: 840, Score: 0.1, Avg Score: -4.5\n",
      "Episode: 850, Score: 8.4, Avg Score: -4.1\n",
      "Episode: 860, Score: -0.4, Avg Score: -4.0\n",
      "Episode: 870, Score: -6.8, Avg Score: -3.9\n",
      "Episode: 880, Score: -0.9, Avg Score: -3.9\n",
      "Episode: 890, Score: -7.2, Avg Score: -4.1\n",
      "Episode: 900, Score: 3.2, Avg Score: -4.1\n",
      "Episode: 910, Score: -7.3, Avg Score: -4.0\n",
      "Episode: 920, Score: -1.5, Avg Score: -3.8\n",
      "Episode: 930, Score: -7.2, Avg Score: -4.1\n",
      "Episode: 940, Score: 0.0, Avg Score: -3.8\n",
      "Episode: 950, Score: -0.5, Avg Score: -4.4\n",
      "Episode: 960, Score: -6.1, Avg Score: -4.7\n",
      "Episode: 970, Score: -5.2, Avg Score: -4.9\n",
      "Episode: 980, Score: 5.1, Avg Score: -4.9\n",
      "Episode: 990, Score: -7.5, Avg Score: -5.0\n",
      "Episode: 1000, Score: 3.9, Avg Score: -5.0\n",
      "Episode: 1010, Score: -6.9, Avg Score: -5.1\n",
      "Episode: 1020, Score: -8.6, Avg Score: -5.2\n",
      "Episode: 1030, Score: -4.0, Avg Score: -5.1\n",
      "Episode: 1040, Score: -5.4, Avg Score: -5.3\n",
      "Episode: 1050, Score: -9.1, Avg Score: -4.9\n",
      "Episode: 1060, Score: -6.5, Avg Score: -5.1\n",
      "Episode: 1070, Score: -8.9, Avg Score: -5.1\n",
      "Episode: 1080, Score: -1.2, Avg Score: -5.2\n",
      "Episode: 1090, Score: -2.9, Avg Score: -5.2\n",
      "Episode: 1100, Score: -4.4, Avg Score: -5.6\n",
      "Episode: 1110, Score: -3.0, Avg Score: -5.7\n",
      "Episode: 1120, Score: -7.0, Avg Score: -5.9\n",
      "Episode: 1130, Score: -6.6, Avg Score: -6.1\n",
      "Episode: 1140, Score: -6.4, Avg Score: -6.2\n",
      "Episode: 1150, Score: -1.1, Avg Score: -6.5\n",
      "Episode: 1160, Score: -7.1, Avg Score: -6.5\n",
      "Episode: 1170, Score: -6.6, Avg Score: -6.7\n",
      "Episode: 1180, Score: -6.8, Avg Score: -6.9\n",
      "Episode: 1190, Score: -11.6, Avg Score: -6.9\n",
      "Episode: 1200, Score: -5.3, Avg Score: -6.6\n",
      "Episode: 1210, Score: -6.4, Avg Score: -6.5\n",
      "Episode: 1220, Score: -6.6, Avg Score: -6.3\n",
      "Episode: 1230, Score: -8.7, Avg Score: -6.3\n",
      "Episode: 1240, Score: -8.3, Avg Score: -6.2\n",
      "Episode: 1250, Score: -5.8, Avg Score: -6.3\n",
      "Episode: 1260, Score: -6.2, Avg Score: -6.3\n",
      "Episode: 1270, Score: -3.2, Avg Score: -6.0\n",
      "Episode: 1280, Score: -0.6, Avg Score: -5.9\n",
      "Episode: 1290, Score: -5.4, Avg Score: -5.6\n",
      "Episode: 1300, Score: -2.5, Avg Score: -5.7\n",
      "Episode: 1310, Score: -1.9, Avg Score: -5.7\n",
      "Episode: 1320, Score: -7.0, Avg Score: -5.5\n",
      "Episode: 1330, Score: 2.2, Avg Score: -5.6\n",
      "Episode: 1340, Score: -7.9, Avg Score: -5.6\n",
      "Episode: 1350, Score: -9.2, Avg Score: -5.6\n",
      "Episode: 1360, Score: -5.4, Avg Score: -5.6\n",
      "Episode: 1370, Score: -6.4, Avg Score: -5.5\n",
      "Episode: 1380, Score: -6.4, Avg Score: -5.3\n",
      "Episode: 1390, Score: -6.8, Avg Score: -5.5\n",
      "Episode: 1400, Score: -1.8, Avg Score: -5.4\n",
      "Episode: 1410, Score: -9.5, Avg Score: -5.4\n",
      "Episode: 1420, Score: -7.7, Avg Score: -5.4\n",
      "Episode: 1430, Score: -8.8, Avg Score: -5.1\n",
      "Episode: 1440, Score: -7.6, Avg Score: -4.8\n",
      "Episode: 1450, Score: -2.2, Avg Score: -4.6\n",
      "Episode: 1460, Score: -8.8, Avg Score: -4.5\n",
      "Episode: 1470, Score: -6.8, Avg Score: -4.6\n",
      "Episode: 1480, Score: -0.8, Avg Score: -4.5\n",
      "Episode: 1490, Score: -1.2, Avg Score: -4.5\n",
      "Episode: 1500, Score: -5.2, Avg Score: -4.5\n",
      "Episode: 1510, Score: -8.4, Avg Score: -4.5\n",
      "Episode: 1520, Score: -6.5, Avg Score: -4.6\n",
      "Episode: 1530, Score: -7.6, Avg Score: -4.6\n",
      "Episode: 1540, Score: -7.6, Avg Score: -4.8\n",
      "Episode: 1550, Score: -8.3, Avg Score: -4.8\n",
      "Episode: 1560, Score: -4.9, Avg Score: -4.7\n",
      "Episode: 1570, Score: -8.9, Avg Score: -4.8\n",
      "Episode: 1580, Score: -4.3, Avg Score: -4.8\n",
      "Episode: 1590, Score: -8.4, Avg Score: -4.6\n",
      "Episode: 1600, Score: -7.1, Avg Score: -4.7\n",
      "Episode: 1610, Score: -3.2, Avg Score: -4.7\n",
      "Episode: 1620, Score: -6.0, Avg Score: -4.8\n",
      "Episode: 1630, Score: -5.7, Avg Score: -5.0\n",
      "Episode: 1640, Score: -2.1, Avg Score: -5.0\n",
      "Episode: 1650, Score: -6.0, Avg Score: -4.9\n",
      "Episode: 1660, Score: -6.2, Avg Score: -5.1\n",
      "Episode: 1670, Score: -5.4, Avg Score: -5.0\n",
      "Episode: 1680, Score: -7.6, Avg Score: -5.1\n",
      "Episode: 1690, Score: -10.0, Avg Score: -5.2\n",
      "Episode: 1700, Score: 0.6, Avg Score: -5.0\n",
      "Episode: 1710, Score: 0.4, Avg Score: -5.0\n",
      "Episode: 1720, Score: 3.1, Avg Score: -4.9\n",
      "Episode: 1730, Score: -6.9, Avg Score: -4.5\n",
      "Episode: 1740, Score: -0.2, Avg Score: -4.3\n",
      "Episode: 1750, Score: -4.9, Avg Score: -4.2\n",
      "Episode: 1760, Score: -8.5, Avg Score: -4.2\n",
      "Episode: 1770, Score: -8.8, Avg Score: -4.4\n",
      "Episode: 1780, Score: 0.3, Avg Score: -4.5\n",
      "Episode: 1790, Score: -6.3, Avg Score: -4.4\n",
      "Episode: 1800, Score: -8.2, Avg Score: -4.8\n",
      "Episode: 1810, Score: -2.1, Avg Score: -4.8\n",
      "Episode: 1820, Score: -0.5, Avg Score: -4.7\n",
      "Episode: 1830, Score: -5.8, Avg Score: -4.9\n",
      "Episode: 1840, Score: 2.7, Avg Score: -5.2\n",
      "Episode: 1850, Score: -8.6, Avg Score: -5.3\n",
      "Episode: 1860, Score: -1.7, Avg Score: -5.0\n",
      "Episode: 1870, Score: -3.4, Avg Score: -4.8\n",
      "Episode: 1880, Score: -0.8, Avg Score: -4.6\n",
      "Episode: 1890, Score: -7.4, Avg Score: -4.6\n",
      "Episode: 1900, Score: -8.6, Avg Score: -4.4\n",
      "Episode: 1910, Score: -7.2, Avg Score: -4.3\n",
      "Episode: 1920, Score: -1.8, Avg Score: -4.5\n",
      "Episode: 1930, Score: -0.8, Avg Score: -4.4\n",
      "Episode: 1940, Score: -3.3, Avg Score: -4.3\n",
      "Episode: 1950, Score: 0.1, Avg Score: -4.4\n",
      "Episode: 1960, Score: -1.0, Avg Score: -4.6\n",
      "Episode: 1970, Score: -1.0, Avg Score: -4.7\n",
      "Episode: 1980, Score: -3.3, Avg Score: -4.8\n",
      "Episode: 1990, Score: -6.5, Avg Score: -4.8\n",
      "Episode: 2000, Score: -1.1, Avg Score: -4.7\n",
      "Episode: 2010, Score: -0.7, Avg Score: -4.8\n",
      "Episode: 2020, Score: -8.0, Avg Score: -4.7\n",
      "Episode: 2030, Score: -8.9, Avg Score: -4.8\n",
      "Episode: 2040, Score: 4.5, Avg Score: -4.6\n",
      "Episode: 2050, Score: -2.8, Avg Score: -4.7\n",
      "Episode: 2060, Score: 4.6, Avg Score: -4.7\n",
      "Episode: 2070, Score: -8.1, Avg Score: -4.8\n",
      "Episode: 2080, Score: -6.2, Avg Score: -4.8\n",
      "Episode: 2090, Score: -7.4, Avg Score: -4.9\n",
      "Episode: 2100, Score: -7.2, Avg Score: -5.0\n",
      "Episode: 2110, Score: -6.0, Avg Score: -5.0\n",
      "Episode: 2120, Score: -8.7, Avg Score: -5.0\n",
      "Episode: 2130, Score: -5.4, Avg Score: -5.1\n",
      "Episode: 2140, Score: -1.2, Avg Score: -5.4\n",
      "Episode: 2150, Score: -6.4, Avg Score: -5.4\n",
      "Episode: 2160, Score: -5.8, Avg Score: -5.0\n",
      "Episode: 2170, Score: -7.1, Avg Score: -4.7\n",
      "Episode: 2180, Score: -6.7, Avg Score: -4.9\n",
      "Episode: 2190, Score: -1.7, Avg Score: -4.7\n",
      "Episode: 2200, Score: -6.4, Avg Score: -4.5\n",
      "Episode: 2210, Score: -6.2, Avg Score: -4.5\n",
      "Episode: 2220, Score: -1.8, Avg Score: -4.3\n",
      "Episode: 2230, Score: -0.5, Avg Score: -4.2\n",
      "Episode: 2240, Score: -5.1, Avg Score: -4.1\n",
      "Episode: 2250, Score: 10.2, Avg Score: -4.0\n",
      "Episode: 2260, Score: 6.1, Avg Score: -4.3\n",
      "Episode: 2270, Score: 6.5, Avg Score: -4.3\n",
      "Episode: 2280, Score: -5.3, Avg Score: -4.2\n",
      "Episode: 2290, Score: -5.7, Avg Score: -4.2\n",
      "Episode: 2300, Score: -2.7, Avg Score: -4.3\n",
      "Episode: 2310, Score: -1.2, Avg Score: -4.6\n",
      "Episode: 2320, Score: -1.1, Avg Score: -4.7\n",
      "Episode: 2330, Score: -0.6, Avg Score: -4.6\n",
      "Episode: 2340, Score: -1.2, Avg Score: -4.7\n",
      "Episode: 2350, Score: 10.6, Avg Score: -4.4\n",
      "Episode: 2360, Score: -2.5, Avg Score: -4.3\n",
      "Episode: 2370, Score: -6.6, Avg Score: -4.4\n",
      "Episode: 2380, Score: -4.8, Avg Score: -4.4\n",
      "Episode: 2390, Score: -7.2, Avg Score: -4.8\n",
      "Episode: 2400, Score: -6.5, Avg Score: -4.8\n",
      "Episode: 2410, Score: 3.8, Avg Score: -4.6\n",
      "Episode: 2420, Score: -2.9, Avg Score: -4.4\n",
      "Episode: 2430, Score: -0.4, Avg Score: -4.2\n",
      "Episode: 2440, Score: -6.0, Avg Score: -4.2\n",
      "Episode: 2450, Score: -6.2, Avg Score: -4.4\n",
      "Episode: 2460, Score: -6.6, Avg Score: -4.6\n",
      "Episode: 2470, Score: -7.2, Avg Score: -4.6\n",
      "Episode: 2480, Score: -3.0, Avg Score: -4.3\n",
      "Episode: 2490, Score: -1.4, Avg Score: -4.1\n",
      "Episode: 2500, Score: -7.5, Avg Score: -3.8\n",
      "Episode: 2510, Score: -5.0, Avg Score: -3.8\n",
      "Episode: 2520, Score: -8.1, Avg Score: -4.0\n",
      "Episode: 2530, Score: -6.5, Avg Score: -4.1\n",
      "Episode: 2540, Score: -9.0, Avg Score: -4.2\n",
      "Episode: 2550, Score: -0.6, Avg Score: -4.1\n",
      "Episode: 2560, Score: -1.7, Avg Score: -4.1\n",
      "Episode: 2570, Score: -1.4, Avg Score: -4.1\n",
      "Episode: 2580, Score: -2.2, Avg Score: -4.5\n",
      "Episode: 2590, Score: -13.9, Avg Score: -4.5\n",
      "Episode: 2600, Score: -6.2, Avg Score: -4.7\n",
      "Episode: 2610, Score: -2.6, Avg Score: -4.8\n",
      "Episode: 2620, Score: -1.3, Avg Score: -4.6\n",
      "Episode: 2630, Score: -6.4, Avg Score: -4.5\n",
      "Episode: 2640, Score: -2.2, Avg Score: -4.4\n",
      "Episode: 2650, Score: 3.6, Avg Score: -4.4\n",
      "Episode: 2660, Score: -4.8, Avg Score: -4.2\n",
      "Episode: 2670, Score: -7.7, Avg Score: -4.1\n",
      "Episode: 2680, Score: -5.2, Avg Score: -3.7\n",
      "Episode: 2690, Score: -0.4, Avg Score: -3.7\n",
      "Episode: 2700, Score: 5.7, Avg Score: -3.5\n",
      "Episode: 2710, Score: -4.4, Avg Score: -3.6\n",
      "Episode: 2720, Score: -0.8, Avg Score: -4.2\n",
      "Episode: 2730, Score: -3.3, Avg Score: -4.4\n",
      "Episode: 2740, Score: -5.6, Avg Score: -4.5\n",
      "Episode: 2750, Score: -2.6, Avg Score: -4.6\n",
      "Episode: 2760, Score: -5.2, Avg Score: -4.2\n",
      "Episode: 2770, Score: -5.2, Avg Score: -4.3\n",
      "Episode: 2780, Score: -2.0, Avg Score: -4.5\n",
      "Episode: 2790, Score: -8.8, Avg Score: -4.6\n",
      "Episode: 2800, Score: -5.2, Avg Score: -4.9\n",
      "Episode: 2810, Score: -6.2, Avg Score: -5.1\n",
      "Episode: 2820, Score: -5.6, Avg Score: -4.8\n",
      "Episode: 2830, Score: -2.2, Avg Score: -4.7\n",
      "Episode: 2840, Score: -6.6, Avg Score: -4.6\n",
      "Episode: 2850, Score: -8.0, Avg Score: -4.8\n",
      "Episode: 2860, Score: -1.6, Avg Score: -5.1\n",
      "Episode: 2870, Score: -6.2, Avg Score: -5.1\n",
      "Episode: 2880, Score: -6.8, Avg Score: -5.0\n",
      "Episode: 2890, Score: -0.7, Avg Score: -5.0\n",
      "Episode: 2900, Score: -5.8, Avg Score: -4.7\n",
      "Episode: 2910, Score: 0.6, Avg Score: -4.7\n",
      "Episode: 2920, Score: -5.6, Avg Score: -4.8\n",
      "Episode: 2930, Score: -6.7, Avg Score: -4.8\n",
      "Episode: 2940, Score: -7.5, Avg Score: -4.9\n",
      "Episode: 2950, Score: -3.4, Avg Score: -4.7\n",
      "Episode: 2960, Score: -0.8, Avg Score: -4.9\n",
      "Episode: 2970, Score: -8.2, Avg Score: -4.8\n",
      "Episode: 2980, Score: -7.9, Avg Score: -4.8\n",
      "Episode: 2990, Score: -6.6, Avg Score: -4.5\n",
      "Episode: 3000, Score: -5.8, Avg Score: -4.7\n",
      "Episode: 3010, Score: -1.2, Avg Score: -4.5\n",
      "Episode: 3020, Score: -6.6, Avg Score: -4.3\n",
      "Episode: 3030, Score: -9.0, Avg Score: -4.2\n",
      "Episode: 3040, Score: -4.4, Avg Score: -4.2\n",
      "Episode: 3050, Score: -5.7, Avg Score: -4.2\n",
      "Episode: 3060, Score: -6.9, Avg Score: -4.0\n",
      "Episode: 3070, Score: -6.1, Avg Score: -4.2\n",
      "Episode: 3080, Score: -0.2, Avg Score: -4.1\n",
      "Episode: 3090, Score: -1.3, Avg Score: -4.3\n",
      "Episode: 3100, Score: -2.1, Avg Score: -4.3\n",
      "Episode: 3110, Score: -7.0, Avg Score: -4.6\n",
      "Episode: 3120, Score: 0.3, Avg Score: -4.8\n",
      "Episode: 3130, Score: -1.1, Avg Score: -4.9\n",
      "Episode: 3140, Score: -8.3, Avg Score: -4.9\n",
      "Episode: 3150, Score: -0.7, Avg Score: -4.9\n",
      "Episode: 3160, Score: -2.0, Avg Score: -4.9\n",
      "Episode: 3170, Score: -7.2, Avg Score: -4.6\n",
      "Episode: 3180, Score: -5.5, Avg Score: -4.6\n",
      "Episode: 3190, Score: -7.6, Avg Score: -4.6\n",
      "Episode: 3200, Score: -8.5, Avg Score: -4.6\n",
      "Episode: 3210, Score: -7.2, Avg Score: -4.3\n",
      "Episode: 3220, Score: -6.6, Avg Score: -4.3\n",
      "Episode: 3230, Score: -5.8, Avg Score: -4.3\n",
      "Episode: 3240, Score: -9.0, Avg Score: -4.2\n",
      "Episode: 3250, Score: -8.4, Avg Score: -4.5\n",
      "Episode: 3260, Score: -0.3, Avg Score: -4.4\n",
      "Episode: 3270, Score: -7.8, Avg Score: -4.6\n",
      "Episode: 3280, Score: -9.3, Avg Score: -5.0\n",
      "Episode: 3290, Score: 0.2, Avg Score: -4.9\n",
      "Episode: 3300, Score: -7.6, Avg Score: -4.8\n",
      "Episode: 3310, Score: 5.3, Avg Score: -4.8\n",
      "Episode: 3320, Score: -0.8, Avg Score: -4.8\n",
      "Episode: 3330, Score: -7.5, Avg Score: -4.5\n",
      "Episode: 3340, Score: -7.6, Avg Score: -4.6\n",
      "Episode: 3350, Score: -8.9, Avg Score: -4.5\n",
      "Episode: 3360, Score: -7.5, Avg Score: -4.8\n",
      "Episode: 3370, Score: -7.3, Avg Score: -4.9\n",
      "Episode: 3380, Score: -6.4, Avg Score: -4.7\n",
      "Episode: 3390, Score: 6.5, Avg Score: -4.6\n",
      "Episode: 3400, Score: -2.9, Avg Score: -4.8\n",
      "Episode: 3410, Score: -0.5, Avg Score: -4.9\n",
      "Episode: 3420, Score: -6.7, Avg Score: -4.9\n",
      "Episode: 3430, Score: -8.6, Avg Score: -5.2\n",
      "Episode: 3440, Score: -5.7, Avg Score: -5.0\n",
      "Episode: 3450, Score: -6.3, Avg Score: -5.0\n",
      "Episode: 3460, Score: -1.8, Avg Score: -4.9\n",
      "Episode: 3470, Score: -7.9, Avg Score: -5.0\n",
      "Episode: 3480, Score: -5.7, Avg Score: -5.1\n",
      "Episode: 3490, Score: -7.0, Avg Score: -5.1\n"
     ]
    }
   ],
   "source": [
    "def train_agents(env, agents, n_episodes=1000, save_interval=100, checkpoint_dir='checkpoints'):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    best_reward = -np.inf\n",
    "    score_history = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            actions = {}\n",
    "            for agent_id, agent in enumerate(agents):\n",
    "                # Get observation for the specific agent\n",
    "                observation = obs[agent_id]\n",
    "                action, prob, val = agent.choose_action(observation)\n",
    "                actions[agent_id] = action\n",
    "                \n",
    "            next_obs, rewards, dones, truncated, _ = env.step(actions)\n",
    "            \n",
    "            # Store transitions in agents' memories\n",
    "            for agent_id, agent in enumerate(agents):\n",
    "                agent.remember(obs[agent_id], actions[agent_id], prob, val, rewards[agent_id], dones[agent_id])\n",
    "                score += rewards[agent_id]\n",
    "            \n",
    "            # Update observations\n",
    "            obs = next_obs\n",
    "            done = dones[\"__all__\"]\n",
    "        \n",
    "        # Learning step for all agents after episode completion\n",
    "        for agent in agents:\n",
    "            agent.learn()\n",
    "        \n",
    "        score_history.append(score)\n",
    "        avg_score = np.mean(score_history[-100:]) if len(score_history) >= 100 else np.mean(score_history)\n",
    "        \n",
    "        if episode % 10 == 0:\n",
    "            print(f'Episode: {episode}, Score: {score:.1f}, Avg Score: {avg_score:.1f}')\n",
    "        \n",
    "        # Save models if performance improves\n",
    "        if avg_score > best_reward and episode > 100:\n",
    "            best_reward = avg_score\n",
    "            for agent_id, agent in enumerate(agents):\n",
    "                agent.save_models(os.path.join(checkpoint_dir, f'agent_{agent_id}'))\n",
    "        \n",
    "        # Regular checkpoint saving\n",
    "        if episode % save_interval == 0 and episode > 0:\n",
    "            checkpoint_episode_dir = os.path.join(checkpoint_dir, f'checkpoint_{episode}')\n",
    "            os.makedirs(checkpoint_episode_dir, exist_ok=True)\n",
    "            for agent_id, agent in enumerate(agents):\n",
    "                agent.save_models(os.path.join(checkpoint_episode_dir, f'agent_{agent_id}'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Train multi-agent delivery bots')\n",
    "    parser.add_argument('--grid_size', type=int, default=10, help='Size of the grid world')\n",
    "    parser.add_argument('--num_agents', type=int, default=4, help='Number of agents')\n",
    "    parser.add_argument('--num_packages', type=int, default=8, help='Number of packages')\n",
    "    parser.add_argument('--episodes', type=int, default=2000, help='Number of training episodes')\n",
    "    parser.add_argument('--save_interval', type=int, default=200, help='Episodes between checkpoints')\n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    # Create environment\n",
    "    env = DeliveryGridWorld(\n",
    "        grid_size=args.grid_size,\n",
    "        num_agents=args.num_agents,\n",
    "        num_packages=args.num_packages\n",
    "    )\n",
    "    \n",
    "    # Create a temporary observation to get the actual observation size\n",
    "    temp_obs, _ = env.reset()\n",
    "    obs_dim = temp_obs[0].shape[0]  # Get the size of one agent's observation\n",
    "    \n",
    "    # Create agents with the correct input dimensions\n",
    "    agents = []\n",
    "    for _ in range(args.num_agents):\n",
    "        agent = Agent(\n",
    "            input_dims=obs_dim,\n",
    "            n_actions=env.action_space.n,\n",
    "            batch_size=64,\n",
    "            alpha=0.0003,\n",
    "            gamma=0.99\n",
    "        )\n",
    "        agents.append(agent)\n",
    "    \n",
    "\n",
    "    args.episodes = 3500\n",
    "    # Train agents\n",
    "    train_agents(\n",
    "        env=env,\n",
    "        agents=agents,\n",
    "        n_episodes=args.episodes,\n",
    "        save_interval=args.save_interval\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f729e4",
   "metadata": {},
   "source": [
    "## Preparing Config Files for Sumo Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecef24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import traci\n",
    "import traci.constants as tc\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "# from delivery_environment import DeliveryGridWorld\n",
    "\n",
    "def generate_sumo_config(grid_size, temp_dir):\n",
    "    \"\"\"Generate SUMO configuration files for visualization.\"\"\"\n",
    "    \n",
    "    # Scale factor to make the grid visualization better in SUMO\n",
    "    scale = 1 # enlarges 10 times\n",
    "    \n",
    "    # Create nodes file\n",
    "    nodes_file = os.path.join(temp_dir, \"delivery_grid.nod.xml\")\n",
    "    with open(nodes_file, \"w\") as f:\n",
    "        f.write('<nodes>\\n')\n",
    "        # Create nodes for each intersection in the grid\n",
    "        for y in range(grid_size + 1):\n",
    "            for x in range(grid_size + 1):\n",
    "                f.write(f'    <node id=\"n{x}_{y}\" x=\"{x * scale}\" y=\"{y * scale}\" type=\"priority\"/>\\n')\n",
    "        f.write('</nodes>\\n')\n",
    "    \n",
    "    # Create edges file\n",
    "    edges_file = os.path.join(temp_dir, \"delivery_grid.edg.xml\")\n",
    "    with open(edges_file, \"w\") as f:\n",
    "        f.write('<edges>\\n')\n",
    "        # Create horizontal edges\n",
    "        for y in range(grid_size + 1):\n",
    "            for x in range(grid_size):\n",
    "                f.write(f'    <edge id=\"h{x}_{y}\" from=\"n{x}_{y}\" to=\"n{x+1}_{y}\" numLanes=\"1\" speed=\"13.89\"/>\\n')\n",
    "                f.write(f'    <edge id=\"h{x}_{y}_back\" from=\"n{x+1}_{y}\" to=\"n{x}_{y}\" numLanes=\"1\" speed=\"13.89\"/>\\n')\n",
    "        \n",
    "        # Create vertical edges\n",
    "        for x in range(grid_size + 1):\n",
    "            for y in range(grid_size):\n",
    "                f.write(f'    <edge id=\"v{x}_{y}\" from=\"n{x}_{y}\" to=\"n{x}_{y+1}\" numLanes=\"1\" speed=\"13.89\"/>\\n')\n",
    "                f.write(f'    <edge id=\"v{x}_{y}_back\" from=\"n{x}_{y+1}\" to=\"n{x}_{y}\" numLanes=\"1\" speed=\"13.89\"/>\\n')\n",
    "        f.write('</edges>\\n')\n",
    "    \n",
    "    # Create netconvert command\n",
    "    netconvert_cmd = [\n",
    "        \"netconvert\",\n",
    "        \"--node-files\", nodes_file,\n",
    "        \"--edge-files\", edges_file,\n",
    "        \"--output-file\", os.path.join(temp_dir, \"delivery_grid.net.xml\"),\n",
    "        \"--no-turnarounds\", \"true\"\n",
    "    ]\n",
    "    \n",
    "    # Run netconvert\n",
    "    subprocess.run(netconvert_cmd)\n",
    "    \n",
    "    # Create routes file\n",
    "    routes_file = os.path.join(temp_dir, \"delivery_grid.rou.xml\")\n",
    "    with open(routes_file, \"w\") as f:\n",
    "        f.write('<routes>\\n')\n",
    "        # Define vehicle types - Fix: Use valid SUMO shapes\n",
    "        f.write('    <vType id=\"agent\" length=\"2\" minGap=\"1\" maxSpeed=\"5\" guiShape=\"passenger\" color=\"0,0,255\"/>\\n')\n",
    "        f.write('    <vType id=\"package\" length=\"1\" minGap=\"1\" maxSpeed=\"0.1\" guiShape=\"delivery\" color=\"255,0,0\"/>\\n')\n",
    "        f.write('    <vType id=\"destination\" length=\"1\" minGap=\"1\" maxSpeed=\"0.1\" guiShape=\"truck\" color=\"0,255,0\"/>\\n')\n",
    "        \n",
    "        # Create a route that covers the entire grid\n",
    "        f.write('    <route id=\"grid_route\" edges=\"')\n",
    "        for y in range(grid_size + 1):\n",
    "            for x in range(grid_size):\n",
    "                f.write(f\"h{x}_{y} \")\n",
    "            if y < grid_size:\n",
    "                f.write(f\"v{grid_size}_{y} \")\n",
    "                for x in range(grid_size-1, -1, -1):\n",
    "                    f.write(f\"h{x}_{y+1}_back \")\n",
    "                if y < grid_size-1:\n",
    "                    f.write(f\"v0_{y+1}_back \")\n",
    "        f.write('\"/>\\n')\n",
    "        f.write('</routes>\\n')\n",
    "    \n",
    "    # Create SUMO configuration file\n",
    "    sumo_config = os.path.join(temp_dir, \"delivery_grid.sumocfg\")\n",
    "    with open(sumo_config, \"w\") as f:\n",
    "        f.write('<configuration>\\n')\n",
    "        f.write('    <input>\\n')\n",
    "        f.write(f'        <net-file value=\"delivery_grid.net.xml\"/>\\n')\n",
    "        f.write(f'        <route-files value=\"delivery_grid.rou.xml\"/>\\n')\n",
    "        f.write('    </input>\\n')\n",
    "        f.write('    <time>\\n')\n",
    "        f.write('        <begin value=\"0\"/>\\n')\n",
    "        f.write('        <end value=\"1000\"/>\\n')\n",
    "        f.write('    </time>\\n')\n",
    "        f.write('</configuration>\\n')\n",
    "    \n",
    "    return sumo_config\n",
    "\n",
    "def get_nearest_edge(x, y, grid_size, scale=100):\n",
    "    \"\"\"Get the nearest edge ID for a given position.\"\"\"\n",
    "    # Find nearest node coordinates\n",
    "    node_x = round(x / scale) * scale\n",
    "    node_y = round(y / scale) * scale\n",
    "    \n",
    "    # Convert to node indices\n",
    "    nx = int(node_x / scale)\n",
    "    ny = int(node_y / scale)\n",
    "    \n",
    "    # Ensure we're within bounds\n",
    "    nx = max(0, min(nx, grid_size))\n",
    "    ny = max(0, min(ny, grid_size))\n",
    "    \n",
    "    # Determine which edge to use based on proximity to the nearest node\n",
    "    if abs(x - node_x) > abs(y - node_y):\n",
    "        # Closer to horizontal edge\n",
    "        if x > node_x and nx < grid_size:\n",
    "            return f\"h{nx}_{ny}\"\n",
    "        elif nx > 0:\n",
    "            return f\"h{nx-1}_{ny}_back\"\n",
    "    else:\n",
    "        # Closer to vertical edge\n",
    "        if y > node_y and ny < grid_size:\n",
    "            return f\"v{nx}_{ny}\"\n",
    "        elif ny > 0:\n",
    "            return f\"v{nx}_{ny-1}_back\"\n",
    "    \n",
    "    # Fallback to a default edge\n",
    "    if grid_size > 0:\n",
    "        return f\"h0_0\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def update_sumo_visualization(env):\n",
    "    \"\"\"Create a completely new visualization from scratch each time.\"\"\"\n",
    "    # Remove all existing vehicles first\n",
    "    for veh_id in traci.vehicle.getIDList():\n",
    "        traci.vehicle.remove(veh_id)\n",
    "    \n",
    "    scale = 100  # Scale factor for visualization\n",
    "    \n",
    "    # Add agents as vehicles with distinctive appearance\n",
    "    for i, pos in enumerate(env.agent_positions):\n",
    "        agent_id = f\"agent_{i}\"\n",
    "        x, y = pos\n",
    "        sumo_x = x * scale + scale/2\n",
    "        sumo_y = y * scale + scale/2\n",
    "        \n",
    "        # Add vehicle\n",
    "        traci.vehicle.add(agent_id, \"grid_route\", typeID=\"agent\")\n",
    "        traci.vehicle.moveToXY(agent_id, \"\", 0, sumo_x, sumo_y, angle=0, keepRoute=2)\n",
    "        \n",
    "        # Make it more visible\n",
    "        traci.vehicle.setColor(agent_id, (0, 0, 255, 255))  # Blue\n",
    "        traci.vehicle.setWidth(agent_id, 10.0)  # Much wider\n",
    "        traci.vehicle.setLength(agent_id, 16.0)  # Much longer\n",
    "        \n",
    "        # Change color if carrying a package\n",
    "        if env.agent_carrying[i] is not None:\n",
    "            traci.vehicle.setColor(agent_id, (255, 0, 255, 255))  # Purple when carrying\n",
    "    \n",
    "    # Add packages as polygons\n",
    "    for i, pos in enumerate(env.packages):\n",
    "        pkg_id = f\"package_{i}\"\n",
    "        \n",
    "        # Only show if not picked up or delivered\n",
    "        if env.package_status[i] == 0:  # Not picked up yet\n",
    "            x, y = pos\n",
    "            sumo_x = x * scale + scale/2\n",
    "            sumo_y = y * scale + scale/2\n",
    "            \n",
    "            # Create a square polygon\n",
    "            size = 10  # Size of the square\n",
    "            shape = [(sumo_x-size, sumo_y-size), \n",
    "                     (sumo_x+size, sumo_y-size),\n",
    "                     (sumo_x+size, sumo_y+size),\n",
    "                     (sumo_x-size, sumo_y+size)]\n",
    "            \n",
    "            # Remove if already exists\n",
    "            if pkg_id in traci.polygon.getIDList():\n",
    "                traci.polygon.remove(pkg_id)\n",
    "                \n",
    "            # Add polygon\n",
    "            traci.polygon.add(pkg_id, shape, (255, 0, 0, 255), True, \"\")\n",
    "    \n",
    "    # Add destinations as polygons\n",
    "    for i, pos in enumerate(env.destinations):\n",
    "        dest_id = f\"dest_{i}\"\n",
    "        x, y = pos\n",
    "        sumo_x = x * scale + scale/2\n",
    "        sumo_y = y * scale + scale/2\n",
    "        \n",
    "        # Create a square polygon\n",
    "        size = 15  # Size of the square\n",
    "        shape = [(sumo_x-size, sumo_y-size), \n",
    "                 (sumo_x+size, sumo_y-size),\n",
    "                 (sumo_x+size, sumo_y+size),\n",
    "                 (sumo_x-size, sumo_y+size)]\n",
    "        \n",
    "        # Remove if already exists\n",
    "        if dest_id in traci.polygon.getIDList():\n",
    "            traci.polygon.remove(dest_id)\n",
    "            \n",
    "        # Add polygon\n",
    "        traci.polygon.add(dest_id, shape, (0, 255, 0, 255), True, \"\")\n",
    "\n",
    "def generate_sumo_config(grid_size, temp_dir):\n",
    "    \"\"\"Generate SUMO configuration files for visualization.\"\"\"\n",
    "    \n",
    "    # Scale factor to make the grid visualization better in SUMO\n",
    "    scale = 100\n",
    "    \n",
    "    # Create nodes file\n",
    "    nodes_file = os.path.join(temp_dir, \"delivery_grid.nod.xml\")\n",
    "    with open(nodes_file, \"w\") as f:\n",
    "        f.write('<nodes>\\n')\n",
    "        # Create nodes for each intersection in the grid\n",
    "        for y in range(grid_size + 1):\n",
    "            for x in range(grid_size + 1):\n",
    "                # Make nodes visible\n",
    "                f.write(f'    <node id=\"n{x}_{y}\" x=\"{x * scale}\" y=\"{y * scale}\" type=\"priority\"/>\\n')\n",
    "        f.write('</nodes>\\n')\n",
    "    \n",
    "    # Create edges file\n",
    "    edges_file = os.path.join(temp_dir, \"delivery_grid.edg.xml\")\n",
    "    with open(edges_file, \"w\") as f:\n",
    "        f.write('<edges>\\n')\n",
    "        # Create horizontal edges - just make a simple grid\n",
    "        for y in range(grid_size + 1):\n",
    "            for x in range(grid_size):\n",
    "                f.write(f'    <edge id=\"h{x}_{y}\" from=\"n{x}_{y}\" to=\"n{x+1}_{y}\" numLanes=\"1\" speed=\"13.89\"/>\\n')\n",
    "        \n",
    "        # Create vertical edges\n",
    "        for x in range(grid_size + 1):\n",
    "            for y in range(grid_size):\n",
    "                f.write(f'    <edge id=\"v{x}_{y}\" from=\"n{x}_{y}\" to=\"n{x}_{y+1}\" numLanes=\"1\" speed=\"13.89\"/>\\n')\n",
    "        f.write('</edges>\\n')\n",
    "    \n",
    "    # Create netconvert command - make sure it runs correctly\n",
    "    netconvert_cmd = [\n",
    "        \"netconvert\",\n",
    "        \"--node-files\", nodes_file,\n",
    "        \"--edge-files\", edges_file,\n",
    "        \"--output-file\", os.path.join(temp_dir, \"delivery_grid.net.xml\"),\n",
    "        \"--no-turnarounds\", \"true\"\n",
    "    ]\n",
    "    \n",
    "    # Run netconvert\n",
    "    try:\n",
    "        subprocess.run(netconvert_cmd, check=True)\n",
    "        print(\"SUMO network created successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error creating SUMO network: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Create routes file with a simple route\n",
    "    routes_file = os.path.join(temp_dir, \"delivery_grid.rou.xml\")\n",
    "    with open(routes_file, \"w\") as f:\n",
    "        f.write('<routes>\\n')\n",
    "        # Define vehicle types\n",
    "        f.write('    <vType id=\"agent\" length=\"2\" minGap=\"1\" maxSpeed=\"5\" guiShape=\"passenger\"/>\\n')\n",
    "        \n",
    "        # Create a very simple route - just one edge is enough since we'll use moveToXY\n",
    "        f.write('    <route id=\"grid_route\" edges=\"h0_0\"/>\\n')\n",
    "        f.write('</routes>\\n')\n",
    "    \n",
    "    # Create SUMO configuration file\n",
    "    sumo_config = os.path.join(temp_dir, \"delivery_grid.sumocfg\")\n",
    "    with open(sumo_config, \"w\") as f:\n",
    "        f.write('<configuration>\\n')\n",
    "        f.write('    <input>\\n')\n",
    "        f.write(f'        <net-file value=\"delivery_grid.net.xml\"/>\\n')\n",
    "        f.write(f'        <route-files value=\"delivery_grid.rou.xml\"/>\\n')\n",
    "        f.write('    </input>\\n')\n",
    "        f.write('    <time>\\n')\n",
    "        f.write('        <begin value=\"0\"/>\\n')\n",
    "        f.write('        <end value=\"1000\"/>\\n')\n",
    "        f.write('    </time>\\n')\n",
    "        f.write('    <gui_only>\\n')\n",
    "        f.write('        <gui-settings-file value=\"gui-settings.xml\"/>\\n')\n",
    "        f.write('    </gui_only>\\n')\n",
    "        f.write('</configuration>\\n')\n",
    "    \n",
    "    # Create GUI settings file to improve visibility\n",
    "    gui_settings = os.path.join(temp_dir, \"gui-settings.xml\")\n",
    "    with open(gui_settings, \"w\") as f:\n",
    "        f.write('<viewsettings>\\n')\n",
    "        f.write('    <scheme name=\"real world\"/>\\n')\n",
    "        f.write('    <delay value=\"50\"/>\\n')\n",
    "        f.write('    <viewport zoom=\"100\" x=\"500\" y=\"500\"/>\\n')\n",
    "        f.write('</viewsettings>\\n')\n",
    "    \n",
    "    return sumo_config\n",
    "\n",
    "def run_visualization(model_path, num_agents=4, grid_size=10, num_packages=8, steps=1000, delay=0.5):\n",
    "    scale=100\n",
    "    \"\"\"Run a visualization of the trained agents.\"\"\"\n",
    "    # Create and use a fixed directory for SUMO files\n",
    "    # temp_dir = \"E:/Multi_agent_system DL project/sumo_training\"\n",
    "    temp_dir = \"E:\\Multi-Agent-Bot-Delivery-System\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate SUMO config\n",
    "    sumo_config = generate_sumo_config(grid_size, temp_dir)\n",
    "    if sumo_config is None:\n",
    "        print(\"Failed to create SUMO configuration.\")\n",
    "        return\n",
    "    \n",
    "    # Start SUMO with GUI\n",
    "    try:\n",
    "        # Make sure SUMO is in PATH or provide full path\n",
    "        sumo_binary = \"sumo-gui\"\n",
    "        sumo_cmd = [\n",
    "            sumo_binary, \n",
    "            \"-c\", sumo_config,\n",
    "            \"--start\",  # Start the simulation immediately\n",
    "            \"--quit-on-end\"  # Quit when simulation ends\n",
    "        ]\n",
    "        \n",
    "        # Start SUMO\n",
    "        print(\"Starting SUMO...\")\n",
    "        traci.start(sumo_cmd)\n",
    "        print(\"SUMO started successfully\")\n",
    "        \n",
    "        # Set up environment\n",
    "        env = DeliveryGridWorld(\n",
    "            grid_size=grid_size,\n",
    "            num_agents=num_agents,\n",
    "            num_packages=num_packages\n",
    "        )\n",
    "        \n",
    "        # Load agent models\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        n_actions = env.action_space.n\n",
    "        \n",
    "\n",
    "        # Add this loop to ensure all packages are correctly visualized:\n",
    "        for pkg_idx, status in enumerate(env.package_status):\n",
    "            if status != 0:  # If picked up or delivered\n",
    "                pkg_id = f\"package_{pkg_idx}\"\n",
    "                if pkg_id in traci.polygon.getIDList():\n",
    "                    traci.polygon.remove(pkg_id)\n",
    "                    print(f\"Fixed: Removed package {pkg_idx} from visualization (status={status})\")\n",
    "\n",
    "        agents = []\n",
    "        for i in range(num_agents):\n",
    "            agent = Agent(input_dims=obs_dim, n_actions=n_actions)\n",
    "            agent.load_models(os.path.join(model_path, f'agent_{i}'))\n",
    "            agents.append(agent)\n",
    "        \n",
    "        # Reset environment\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        \n",
    "        # Initial visualization setup\n",
    "        print(\"Setting up visualization...\")\n",
    "        \n",
    "        # Set zoom level\n",
    "        traci.gui.setZoom(\"View #0\", 100)\n",
    "        \n",
    "        # Initial rendering\n",
    "        update_sumo_visualization(env)\n",
    "        traci.simulationStep()\n",
    "        \n",
    "        # Wait a moment for the GUI to initialize\n",
    "        time.sleep(1)\n",
    "        \n",
    "        print(\"Starting simulation run...\")\n",
    "        \n",
    "        while not done and step_count < steps:\n",
    "            if step_count % 10 == 0:\n",
    "                print(f\"\\nStep {step_count}/{steps}\")\n",
    "            \n",
    "            # Get actions from agents\n",
    "            actions = {}\n",
    "            for agent_id, agent in enumerate(agents):\n",
    "                action, _, _ = agent.choose_action(obs[agent_id])\n",
    "                actions[agent_id] = action\n",
    "                print(f\"Agent {agent_id} action: {action}\")\n",
    "            \n",
    "            # Step environment\n",
    "            next_obs, rewards, dones, _, _ = env.step(actions)\n",
    "            \n",
    "            # Print current state\n",
    "            # for i, pos in enumerate(env.agent_positions):\n",
    "            #     carrying = env.agent_carrying[i]\n",
    "            #     carry_str = f\"carrying pkg {carrying}\" if carrying is not None else \"not carrying\"\n",
    "            #     print(f\"Agent {i}: pos={pos}, {carry_str}\")\n",
    "            \n",
    "\n",
    "                # Add packages as polygons\n",
    "            for i, pos in enumerate(env.packages):\n",
    "                pkg_id = f\"package_{i}\"\n",
    "                \n",
    "                # Only show if not picked up or delivered\n",
    "                if env.package_status[i] == 0:  # Not picked up yet\n",
    "                    x, y = pos\n",
    "                    sumo_x = x * scale + scale/2\n",
    "                    sumo_y = y * scale + scale/2\n",
    "                    \n",
    "                    # Create a square polygon\n",
    "                    size = 10  # Size of the square\n",
    "                    shape = [(sumo_x-size, sumo_y-size), \n",
    "                            (sumo_x+size, sumo_y-size),\n",
    "                            (sumo_x+size, sumo_y+size),\n",
    "                            (sumo_x-size, sumo_y+size)]\n",
    "                    \n",
    "                    # Remove if already exists\n",
    "                    if pkg_id in traci.polygon.getIDList():\n",
    "                        traci.polygon.remove(pkg_id)\n",
    "                        \n",
    "                    # Add polygon\n",
    "                    traci.polygon.add(pkg_id, shape, (255, 0, 0, 255), True, \"\")\n",
    "                else:\n",
    "                    # Package is either picked up or delivered - remove from visualization if exists\n",
    "                    if pkg_id in traci.polygon.getIDList():\n",
    "                        traci.polygon.remove(pkg_id)\n",
    "\n",
    "\n",
    "            # Update SUMO visualization from scratch\n",
    "            update_sumo_visualization(env)\n",
    "            \n",
    "            # Update simulation\n",
    "            traci.simulationStep()\n",
    "            \n",
    "            # Update observations\n",
    "            obs = next_obs\n",
    "            done = dones[\"__all__\"]\n",
    "            step_count += 1\n",
    "            \n",
    "            # Add delay to make visualization viewable\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        print(f\"Visualization complete after {step_count} steps\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during visualization: {e}\")\n",
    "    finally:\n",
    "        # Close SUMO connection\n",
    "        if traci.isLoaded():\n",
    "            traci.close()\n",
    "            print(\"SUMO connection closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6391e7fc",
   "metadata": {},
   "source": [
    "## Visualization of agents in sumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac623f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO network created successfully\n",
      "Starting SUMO...\n",
      "SUMO started successfully\n",
      "Environment Reset\n",
      "Grid Size: 10x10\n",
      "Number of Agents: 4\n",
      "Number of Packages: 8\n",
      "Agent Positions: [(np.int64(5), np.int64(0)), (np.int64(3), np.int64(5)), (np.int64(3), np.int64(9)), (np.int64(8), np.int64(5))]\n",
      "Package Positions: [(np.int64(4), np.int64(1)), (np.int64(7), np.int64(3)), (np.int64(2), np.int64(5)), (np.int64(1), np.int64(8)), (np.int64(1), np.int64(1)), (np.int64(0), np.int64(9)), (np.int64(8), np.int64(3)), (np.int64(4), np.int64(2))]\n",
      "Destination Positions: [(np.int64(1), np.int64(3)), (np.int64(5), np.int64(5)), (np.int64(2), np.int64(1)), (np.int64(2), np.int64(2)), (np.int64(4), np.int64(0)), (np.int64(9), np.int64(2)), (np.int64(1), np.int64(9)), (np.int64(3), np.int64(8))]\n",
      "Package-Destination Mapping: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Environment Reset\n",
      "Grid Size: 10x10\n",
      "Number of Agents: 4\n",
      "Number of Packages: 8\n",
      "Agent Positions: [(np.int64(3), np.int64(8)), (np.int64(8), np.int64(9)), (np.int64(6), np.int64(8)), (np.int64(9), np.int64(7))]\n",
      "Package Positions: [(np.int64(0), np.int64(9)), (np.int64(1), np.int64(4)), (np.int64(1), np.int64(7)), (np.int64(5), np.int64(1)), (np.int64(1), np.int64(0)), (np.int64(2), np.int64(6)), (np.int64(1), np.int64(6)), (np.int64(1), np.int64(5))]\n",
      "Destination Positions: [(np.int64(0), np.int64(7)), (np.int64(4), np.int64(4)), (np.int64(4), np.int64(9)), (np.int64(1), np.int64(2)), (np.int64(3), np.int64(2)), (np.int64(2), np.int64(2)), (np.int64(2), np.int64(1)), (np.int64(7), np.int64(4))]\n",
      "Package-Destination Mapping: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Setting up visualization...\n",
      "Starting simulation run...\n",
      "\n",
      "Step 0/500\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 0\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "\n",
      "--- Step 10 ---\n",
      "Agent Positions: [(np.int64(3), 8), (8, 9), (9, np.int64(7)), (9, np.int64(5))]\n",
      "Agent 0 at (np.int64(3), 8) carrying: None\n",
      "Agent 1 at (8, 9) carrying: None\n",
      "Agent 2 at (9, np.int64(7)) carrying: None\n",
      "Agent 3 at (9, np.int64(5)) carrying: None\n",
      "Agent 0 action: 2 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (np.int64(3), 8) to [np.int64(2), 8]\n",
      "Agent 1 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (8, 9) to [8, 8]\n",
      "Agent 2 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, np.int64(7)) to [9, np.int64(7)]\n",
      "Agent 3 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, np.int64(5)) to [9, np.int64(5)]\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 10/500\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "\n",
      "--- Step 20 ---\n",
      "Agent Positions: [(np.int64(2), 5), (5, 9), (6, np.int64(7)), (9, np.int64(3))]\n",
      "Agent 0 at (np.int64(2), 5) carrying: None\n",
      "Agent 1 at (5, 9) carrying: None\n",
      "Agent 2 at (6, np.int64(7)) carrying: None\n",
      "Agent 3 at (9, np.int64(3)) carrying: None\n",
      "Agent 0 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Agent 1 action: 2 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (5, 9) to [4, 9]\n",
      "Agent 2 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (6, np.int64(7)) to [6, np.int64(6)]\n",
      "Agent 3 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, np.int64(3)) to [9, np.int64(3)]\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 20/500\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 0\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 4\n",
      "\n",
      "--- Step 30 ---\n",
      "Agent Positions: [(np.int64(4), 5), (4, 8), (5, np.int64(6)), (9, np.int64(1))]\n",
      "Agent 0 at (np.int64(4), 5) carrying: None\n",
      "Agent 1 at (4, 8) carrying: None\n",
      "Agent 2 at (5, np.int64(6)) carrying: None\n",
      "Agent 3 at (9, np.int64(1)) carrying: None\n",
      "Agent 0 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (np.int64(4), 5) to [np.int64(5), 5]\n",
      "Agent 1 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Agent 2 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Agent 3 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 30/500\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 0\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 1\n",
      "\n",
      "--- Step 40 ---\n",
      "Agent Positions: [(np.int64(5), 3), (5, 8), (9, np.int64(6)), (8, np.int64(2))]\n",
      "Agent 0 at (np.int64(5), 3) carrying: None\n",
      "Agent 1 at (5, 8) carrying: None\n",
      "Agent 2 at (9, np.int64(6)) carrying: None\n",
      "Agent 3 at (8, np.int64(2)) carrying: None\n",
      "Agent 0 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Agent 1 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (5, 8) to [6, 8]\n",
      "Agent 2 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, np.int64(6)) to [9, np.int64(5)]\n",
      "Agent 3 action: 1 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (8, np.int64(2)) to [8, np.int64(3)]\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 40/500\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 0\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "\n",
      "--- Step 50 ---\n",
      "Agent Positions: [(np.int64(5), 3), (6, 9), (7, np.int64(5)), (9, np.int64(2))]\n",
      "Agent 0 at (np.int64(5), 3) carrying: None\n",
      "Agent 1 at (6, 9) carrying: None\n",
      "Agent 2 at (7, np.int64(5)) carrying: None\n",
      "Agent 3 at (9, np.int64(2)) carrying: None\n",
      "Agent 0 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (np.int64(5), 3) to [np.int64(6), 3]\n",
      "Agent 1 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (6, 9) to [6, 8]\n",
      "Agent 2 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (7, np.int64(5)) to [7, np.int64(4)]\n",
      "Agent 3 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, np.int64(2)) to [9, np.int64(2)]\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 50/500\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "\n",
      "--- Step 60 ---\n",
      "Agent Positions: [(np.int64(5), 0), (8, 8), (4, np.int64(3)), (9, 0)]\n",
      "Agent 0 at (np.int64(5), 0) carrying: None\n",
      "Agent 1 at (8, 8) carrying: None\n",
      "Agent 2 at (4, np.int64(3)) carrying: None\n",
      "Agent 3 at (9, 0) carrying: None\n",
      "Agent 0 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (np.int64(5), 0) to [np.int64(5), 0]\n",
      "Agent 1 action: 2 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (8, 8) to [7, 8]\n",
      "Agent 2 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (4, np.int64(3)) to [4, np.int64(2)]\n",
      "Agent 3 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, 0) to [9, 0]\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 60/500\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "\n",
      "--- Step 70 ---\n",
      "Agent Positions: [(np.int64(5), 0), (3, 9), (4, np.int64(2)), (9, 3)]\n",
      "Agent 0 at (np.int64(5), 0) carrying: None\n",
      "Agent 1 at (3, 9) carrying: None\n",
      "Agent 2 at (4, np.int64(2)) carrying: None\n",
      "Agent 3 at (9, 3) carrying: None\n",
      "Agent 0 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (np.int64(5), 0) to [np.int64(6), 0]\n",
      "Agent 1 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Agent 2 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (4, np.int64(2)) to [4, np.int64(1)]\n",
      "Agent 3 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, 3) to [9, 3]\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 70/500\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 0\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 0\n",
      "\n",
      "--- Step 80 ---\n",
      "Agent Positions: [(np.int64(7), 1), (2, 8), (1, 0), (9, 6)]\n",
      "Agent 0 at (np.int64(7), 1) carrying: None\n",
      "Agent 1 at (2, 8) carrying: None\n",
      "Agent 2 at (1, 0) carrying: None\n",
      "Agent 3 at (9, 6) carrying: None\n",
      "Agent 0 action: 2 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (np.int64(7), 1) to [np.int64(6), 1]\n",
      "Agent 1 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Agent 2 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (1, 0) to [1, 0]\n",
      "Agent 3 action: 0 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (9, 6) to [9, 5]\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 80/500\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 1\n",
      "Agent 3 action: 1\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 0\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 4\n",
      "\n",
      "--- Step 90 ---\n",
      "Agent Positions: [(np.int64(5), 1), (0, 8), (2, 4), (9, 3)]\n",
      "Agent 0 at (np.int64(5), 1) carrying: None\n",
      "Agent 1 at (0, 8) carrying: None\n",
      "Agent 2 at (2, 4) carrying: None\n",
      "Agent 3 at (9, 3) carrying: None\n",
      "Agent 0 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (np.int64(5), 1) to [np.int64(6), 1]\n",
      "Agent 1 action: 1 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (0, 8) to [0, 9]\n",
      "Agent 2 action: 3 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "  Moving from (2, 4) to [3, 4]\n",
      "Agent 3 action: 4 (0=Up, 1=Down, 2=Left, 3=Right, 4=Pick/Deliver)\n",
      "Packages delivered: 0/8\n",
      "  Package 0: Not Picked\n",
      "  Package 1: Not Picked\n",
      "  Package 2: Not Picked\n",
      "  Package 3: Not Picked\n",
      "  Package 4: Not Picked\n",
      "  Package 5: Not Picked\n",
      "  Package 6: Not Picked\n",
      "  Package 7: Not Picked\n",
      "\n",
      "Step 90/500\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 3\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 2\n",
      "Agent 0 action: 0\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 4\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 0\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 4\n",
      "Agent 0 action: 1\n",
      "Agent 1 action: 2\n",
      "Agent 2 action: 2\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 2\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 3\n",
      "Agent 1 action: 1\n",
      "Agent 2 action: 3\n",
      "Agent 3 action: 3\n",
      "Agent 0 action: 4\n",
      "Agent 1 action: 4\n",
      "Agent 2 action: 0\n",
      "Agent 3 action: 1\n",
      "Agent 0 picked up package 3 at (np.int64(5), 1)\n",
      "Error during visualization: update_sumo_visualization() takes 1 positional argument but 2 were given\n",
      "SUMO connection closed\n"
     ]
    }
   ],
   "source": [
    "# Main function to run the visualization\n",
    "if __name__ == \"__main__\":\n",
    "    model_path=\"E:/Multi_agent_system DL project/sumo_training/checkpoints/checkpoint_400\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Visualize trained delivery agents in SUMO')\n",
    "    parser.add_argument('--model_path', type=str, help='Path to trained models')\n",
    "    parser.add_argument('--grid_size', type=int, default=10, help='Size of the grid world')\n",
    "    parser.add_argument('--num_agents', type=int, default=4, help='Number of agents')\n",
    "    parser.add_argument('--num_packages', type=int, default=8, help='Number of packages')\n",
    "    parser.add_argument('--steps', type=int, default=500, help='Maximum steps to run')\n",
    "    parser.add_argument('--delay', type=float, default=0.5, help='Delay between steps (seconds)')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    # If not provided externally, set it manually\n",
    "    if args.model_path is None:\n",
    "        args.model_path = model_path\n",
    "    \n",
    "    # args.num_packages = args.num_agents * 2  # Ensure enough packages for agents\n",
    "    \n",
    "    run_visualization(\n",
    "        model_path=args.model_path,\n",
    "        grid_size=args.grid_size,\n",
    "        num_agents=args.num_agents,\n",
    "        \n",
    "        num_packages=args.num_packages,\n",
    "        steps=args.steps,\n",
    "        delay=args.delay\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022dba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9071d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a564d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
